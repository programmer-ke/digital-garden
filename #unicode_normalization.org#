* Unicode normalization             :unicode:normalization:NFC:NFD:NFKC:NFKD:

By Grok

Unicode normalization is a process used to transform equivalent
sequences of Unicode characters into a standard form, ensuring that
text data can be compared or processed consistently across different
systems or applications. Here are explanations for the four main forms
of Unicode normalization:

### 1. **NFC (Normalization Form C - Composition)**

- **What it does**: NFC transforms decomposed characters into their
  precomposed form where possible. This means combining characters and
  diacritics into a single Unicode code point when such a precomposed
  character exists.
  
- **Example**: The character "é" can be represented as a single code
  point U+00E9 (é) or as two code points: U+0065 (e) followed by
  U+0301 (combining acute accent). NFC would choose the single code
  point U+00E9.

- **Use Case**: NFC is often used for text display and in environments
  where you want the most compact representation of text, which can
  also simplify string comparison in some cases.

### 2. **NFD (Normalization Form D - Decomposition)**

- **What it does**: NFD does the opposite of NFC; it decomposes
  combined characters into their base character and separate combining
  marks.

- **Example**: The single character "é" (U+00E9) would be decomposed
  into "e" (U+0065) plus the combining acute accent (U+0301).

- **Use Case**: Useful in linguistic processing or when you need to
  analyze or manipulate diacritical marks separately from their base
  characters.

### 3. **NFKC (Normalization Form KC - Compatibility Composition)**

- **What it does**: NFKC not only composes characters like NFC but
  also replaces compatibility characters with their standard
  equivalents. Compatibility characters are those that have been
  included in Unicode for compatibility with other encoding standards
  but have different representations in Unicode.

- **Example**: The character "ﬃ" (U+FB03, ligature of 'f', 'f', and
  'i') would be decomposed into three separate letters "ffi" in NFD,
  but in NFKC, it would be transformed into the simple sequence "ffi"
  as well, but also any characters like superscript numbers or circled
  letters would be converted to their plain text equivalents.

- **Use Case**: Ideal for search operations or when you need to
  normalize text for comparison where differences in representation
  should be ignored for compatibility reasons.

### 4. **NFKD (Normalization Form KD - Compatibility Decomposition)**

- **What it does**: NFKD decomposes characters like NFD but goes
  further by decomposing compatibility characters into their base
  forms.

- **Example**: Similar to NFD, but with additional steps like
  decomposing the "ﬃ" ligature into "f", "f", "i", and converting
  superscript numbers like "²" to "2".

- **Use Case**: Useful in scenarios where you need to ensure that all
  characters are broken down to their most basic forms for processing,
  like in some forms of text analysis or when ensuring maximum
  compatibility across different systems that might not support newer
  or less common Unicode characters.

### Key Points:

- **Normalization** helps in ensuring that text strings which are
  equivalent but represented differently in Unicode are treated as
  identical for comparison or processing purposes.
- **Choosing the right form** depends on the application: NFC for
  compact, user-friendly text; NFD for detailed character analysis;
  NFKC/NFKD for ensuring compatibility and simplifying text for
  processes like searching or sorting where character variations
  should not affect the outcome.

Each form of normalization has its use cases, and selecting the
appropriate one depends on whether you prioritize composition,
decomposition, compatibility, or a combination thereof for your
specific needs.
