#+FILETAGS: :fastai:machine_learning:deep_learning

* Text models deficiencies                                          :llm:nlp:

Models can generate text that is very compelling yet incorrect. This
is a risk where correctness is very important e.g. precedents in
judgement used in court of law.

A layman may be deceived by very compelling generated information that
only an expert would identify as incorrect.

This has implications on spreading disinformation at a large scale
online, for instance.

* ML Automation                                                  :automation:

In situations where a model might make mistakes, a good alternative to
automating a process is to insert a human into the loop to verify the
model predictions.

Automated alerts from predictions can help timely intervention in
time-sensitive situations, but channelling the alerts through a human
ensures reduces the error rate.

* Tabular Data and Deep learning                       :tabular_data:xgboost:

Generally, tabular data work well with model ensembles like
Xgboost. However, deep learning is suited in cases where certain
columns have a high cardinality (large number of options), or include
info amenable to deep learning such as natural language or images.

The downside is that deep learning models typically take longer to
train than the other methods used for tabular data.

* Deep learning in recommendation systems            :recommendation_systems:

While deep learning may be useful in recommendation systems where
information is represented as a sparse matrix (users as rows, products
as columns), and make recommendations by attempting the fill up the matrix,
they are only good at predicting what a user might like, but not what may
be useful to them.

For example, they may recommend variations of a product already
consoomed, but not an entirely new one that may be useful.

* Steps of the Drivetrain approach       :drivetrain:self_driving:end_to_end:

 1) Identify the objective
 2) Identify levers (controllable actions) that can be used to achieve
    the objective
 3) Collect data needed (existing or new)
 4) Construct the models that can make predictions that lead to the
    appropriate action

In self driving:

 1) Get from A to B without engaging the car
 2) Intercepting the car controls - steering, braking, acceleration...
 3) Collect driving footage, record front-view, rear view, proximity
    sensors etc..
 4) A single model, or model assembly with a simulator (search space
    of possible outcomes) and optimizer (selects best possible
    outcome)

    Question: How does end-to-end learning come into the picture here?
    Possible Answer: End to end learning is an attempt at avoiding
    hand-engineered features in deep learning (information is lost) if
    data is plentiful. Possible approach in here is a single deep
    learning model that is trained straight from all inputs.
    https://stats.stackexchange.com/q/218961

* DataLoaders                       :fastai:dataloader:dataloaders:datablock:

DataLoaders in the fast ai library describe how the data will structured
for use by the model.

They define:
 - What kind of data (inputs and outputs) we're dealing with
 - The path the the dataset
 - How to split the dataset into training and validation sets
 - How to identify the labels for the data
 - Any transformations being performed on the data

The splitter parameter to a DataBlock specifies how the  data will be
divided into training and validation sets.

To ensure a random split always gives the same validation set, we use
a seed which will always generate the same sequence.

* Data augmentation                                       :data_augmentation:

Data augmentation is the process of creating random variations of the
training dataset during the training process to help the model learn
on variations of a specific training input.

For images, this could include rotating, warping, flipping, brightness
and contrast changes.

`item_tfms` in dataloaders specify a transformation applied to a single
item in the training/validation sets.

`batch_tfms` specify transformations applied to an entire batch of the
training data e.g. augmentation.

* Confusion matrix                                         :confusion_matrix:

The confusion matrix analyses the performance of a model and displays
the number of correct/incorrect predictions with labels for each
dimension.

The correct predictions are found along its diagonal.

* learner.export                                       :fastai:export:pickle:

The `export` method on a model saves the model's architecture and
trained parameters in a pickled python file. This will include a
reference to the model's DataLoaders.

* Image Transformations                              :fastai:crop:pad:squish:

When training an image recognition model, the images have to all be
of the same size. This can be done in 3 ways using the fastai library
so that the images can fit the specified dimensions

 - crop :: Cut out parts of the image
 - pad :: Add extra pixels to the image
 - squish :: Re-shape the image

** Risks
 - Cropping may leave out important segments of the image
 - Padding adds unneeded data onto the images. Also, the images may
   now be lower resolution affects learnability
 - Squishing my reshape the objects in a way that doesn't occur in
   real world.

* Inference                                 :inference:production:deployment:

Inference is using a model to getting predictions.


** GPUs vs CPUs in production                                       :cpu:gpu:

A CPU is used while doing inference in production because it is much
less compute intensive than training and CPUs typically have a lower
price than GPUs. 

GPUs can be used in cases where many concurrent inferences are
happening that can justify the addition cost of parallelizing the
inferences. The model may have to be recompiled to support GPU
inferencing, and additional software/hardware infrastructure may be
required to coordinate the batching process.

** Server side vs edge deployment

The models may be deployed either server side or closer to the
customer (edge or mobile device).

The model lifecycle is typically easier to manage if deployed
server side, as well as making it easy to provide the appropriate
resources needed by the model e.g. more expensive hardware for faster
inference.

However some downsides of deploying server side as compared to
client-side (edge or mobile) are:
 - Privacy implications when sending a users' private data to the
   server for inference
 - More difficult horizontal scalability (users use their own hardware
   so it is easier on the service provider.
 - A network connection is required to use the service, and the
   additional roundtrip adds latency to inferencing.

* Possible problems during ml deployment           :deployment:out_of_domain:

Some challenges one could experience in practice while rolling out a
bear warning system trained on images found online are:

 - Working with video data instead of images in the field
 - Images captured by cameras used in the field being of poorer
   quality than the images used in training
 - The need to make predictions based on images capturing different
   angles or different time of day/night than those likely posted online

These are examples of out of domain data, where data different from
that used in training is used for inference.

** Domain shift                                                :domain_shift:

Domain shift occurs where the data seen by the model in production
changes over time and becomes significantly different from that used
in training. An example is where the kind of customer an insurance
company sees changes over time, making the training data outdated.

** Steps in the deployment process to minimise risk

 - Manual deployment :: Human checks all prediction
 - Limited scope deployment :: time or geographical limited deployment
   with careful supervision
 - Gradual roll out :: Increase scope of deployment with reporting and
   alerts set up for any anomalies
