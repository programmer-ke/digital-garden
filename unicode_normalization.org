* Unicode normalization             :unicode:normalization:NFC:NFD:NFKC:NFKD:

By Grok

Unicode normalization is a process used to transform equivalent sequences of Unicode characters into a standard form, ensuring that text data can be compared or processed consistently across different systems or applications. Here are explanations for the four main forms of Unicode normalization:

### 1. **NFC (Normalization Form C - Composition)**

- **What it does**: NFC transforms decomposed characters into their precomposed form where possible. This means combining characters and diacritics into a single Unicode code point when such a precomposed character exists.
  
- **Example**: The character "é" can be represented as a single code point U+00E9 (é) or as two code points: U+0065 (e) followed by U+0301 (combining acute accent). NFC would choose the single code point U+00E9.

- **Use Case**: NFC is often used for text display and in environments where you want the most compact representation of text, which can also simplify string comparison in some cases.

### 2. **NFD (Normalization Form D - Decomposition)**

- **What it does**: NFD does the opposite of NFC; it decomposes combined characters into their base character and separate combining marks.

- **Example**: The single character "é" (U+00E9) would be decomposed into "e" (U+0065) plus the combining acute accent (U+0301).

- **Use Case**: Useful in linguistic processing or when you need to analyze or manipulate diacritical marks separately from their base characters.

### 3. **NFKC (Normalization Form KC - Compatibility Composition)**

- **What it does**: NFKC not only composes characters like NFC but also replaces compatibility characters with their standard equivalents. Compatibility characters are those that have been included in Unicode for compatibility with other encoding standards but have different representations in Unicode.

- **Example**: The character "ﬃ" (U+FB03, ligature of 'f', 'f', and 'i') would be decomposed into three separate letters "ffi" in NFD, but in NFKC, it would be transformed into the simple sequence "ffi" as well, but also any characters like superscript numbers or circled letters would be converted to their plain text equivalents.

- **Use Case**: Ideal for search operations or when you need to normalize text for comparison where differences in representation should be ignored for compatibility reasons.

### 4. **NFKD (Normalization Form KD - Compatibility Decomposition)**

- **What it does**: NFKD decomposes characters like NFD but goes further by decomposing compatibility characters into their base forms.

- **Example**: Similar to NFD, but with additional steps like decomposing the "ﬃ" ligature into "f", "f", "i", and converting superscript numbers like "²" to "2".

- **Use Case**: Useful in scenarios where you need to ensure that all characters are broken down to their most basic forms for processing, like in some forms of text analysis or when ensuring maximum compatibility across different systems that might not support newer or less common Unicode characters.

### Key Points:

- **Normalization** helps in ensuring that text strings which are equivalent but represented differently in Unicode are treated as identical for comparison or processing purposes.
- **Choosing the right form** depends on the application: NFC for compact, user-friendly text; NFD for detailed character analysis; NFKC/NFKD for ensuring compatibility and simplifying text for processes like searching or sorting where character variations should not affect the outcome.

Each form of normalization has its use cases, and selecting the appropriate one depends on whether you prioritize composition, decomposition, compatibility, or a combination thereof for your specific needs.
